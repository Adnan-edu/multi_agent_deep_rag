{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cell-0",
      "metadata": {
        "id": "cell-0"
      },
      "source": [
        "## Image Descriptions with Gemini\n",
        "\n",
        "Generate detailed textual descriptions for extracted images using Gemini 2.5 Flash.\n",
        "\n",
        "**Prerequisites:**\n",
        "- Make sure you rag-data dir with extracted dir like markdown, images and tables\n",
        "- Google API key set in .env file\n",
        "\n",
        "**Output:**\n",
        "- Markdown descriptions saved to `data/rag-data/images_desc/{company}/{document}/page_X.md`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-1",
      "metadata": {
        "id": "cell-1"
      },
      "source": [
        "### Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rcGXTqtQoYbo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rcGXTqtQoYbo",
        "outputId": "3bc50d80-76a2-4a11-e77d-e22a6aa85be2"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv langchain-google-genai Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cell-2",
      "metadata": {
        "id": "cell-2"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from pathlib import Path\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "import base64\n",
        "import io"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-3",
      "metadata": {
        "id": "cell-3"
      },
      "source": [
        "### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "xExihV9loi8Z",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xExihV9loi8Z",
        "outputId": "4c266284-1e2f-4338-b6bc-35ba0541ce96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "cXhfcdq7pPax",
      "metadata": {
        "id": "cXhfcdq7pPax"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "mtysqlTgtaMm",
      "metadata": {
        "id": "mtysqlTgtaMm"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import base64, io\n",
        "from PIL import Image\n",
        "from huggingface_hub import InferenceClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cell-4",
      "metadata": {
        "id": "cell-4"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "IMAGES_DIR = \"/content/drive/MyDrive/Udemy/KGP-TALKIE/Deep_Agent/resources/data/rag-data/images\"\n",
        "OUTPUT_DESC_DIR = \"/content/drive/MyDrive/Udemy/KGP-TALKIE/Deep_Agent/resources/data/rag-data/images_desc\"\n",
        "\n",
        "# Model configuration\n",
        "MODEL_NAME = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
        "client = InferenceClient(model=MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cell-7",
      "metadata": {
        "id": "cell-7"
      },
      "source": [
        "### Description Generation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "390882bc",
      "metadata": {
        "id": "390882bc"
      },
      "outputs": [],
      "source": [
        "describe_image_prompt = \"\"\"Analyze this financial document page and extract meaningful data in a concise format.\n",
        "\n",
        "For charts and graphs:\n",
        "- Identify the metric being measured\n",
        "- List key data points and values\n",
        "- Note significant trends (growth, decline, stability)\n",
        "\n",
        "For tables:\n",
        "- Extract column headers and key rows\n",
        "- Note important values and totals\n",
        "\n",
        "For text:\n",
        "- Summarize key facts and numbers only\n",
        "- Skip formatting, headers, and navigation elements\n",
        "\n",
        "Be direct and factual. Focus on numbers, trends, and insights that would be useful for retrieval.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "baf6e9da",
      "metadata": {
        "id": "baf6e9da"
      },
      "outputs": [],
      "source": [
        "from langchain.messages import SystemMessage\n",
        "\n",
        "\n",
        "def generate_image_description(image_path: Path):\n",
        "    # Load image and convert to base64\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    buffered = io.BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    image_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
        "\n",
        "    # Qwen2.5-VL uses OpenAI-style chat with image + text\n",
        "    response = client.chat.completions.create(\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": \"You are an AI assistant specialized in financial document understanding.\"\n",
        "            },\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": [\n",
        "                    {\"type\": \"text\", \"text\": describe_image_prompt},\n",
        "                    {\n",
        "                        \"type\": \"image_url\",\n",
        "                        \"image_url\": {\n",
        "                            \"url\": f\"data:image/png;base64,{image_base64}\"\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "            }\n",
        "        ],\n",
        "        max_tokens=1200,\n",
        "        temperature=0.2,\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "jacGhxp0pp-S",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jacGhxp0pp-S",
        "outputId": "192a9fb0-63e6-4d5f-c61d-2135463273b0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Udemy/KGP-TALKIE/Deep_Agent/resources/data/rag-data/images'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "IMAGES_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "cell-8",
      "metadata": {
        "id": "cell-8"
      },
      "outputs": [],
      "source": [
        "image_path = Path(r'/content/drive/MyDrive/Udemy/KGP-TALKIE/Deep_Agent/resources/data/rag-data/images/meta/meta 10-k 2024/page_64.png')\n",
        "\n",
        "response = generate_image_description(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "TvX2oPPvqRY2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "TvX2oPPvqRY2",
        "outputId": "d8bfa8ec-4a95-4c4a-ad80-a395d1b7028e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'### Trends in Our Revenue by User Geography\\n\\n**Revenue Worldwide:**\\n- **2022:** $32,165 million\\n- **2023:** $40,111 million\\n- **2024:** $48,385 million\\n- **Growth:** 25% from 2022 to 2024\\n\\n**Revenue US & Canada:**\\n- **2022:** $15,005 million\\n- **2023:** $17,842 million\\n- **2024:** $21,783 million\\n- **Growth:** 19% from 2022 to 2024\\n\\n**Revenue Europe:**\\n- **2022:** $7,050 million\\n- **2023:** $7,777 million\\n- **2024:** $11,503 million\\n- **Growth:** 66% from 2022 to 2024\\n\\n**Revenue Asia-Pacific:**\\n- **2022:** $5,968 million\\n- **2023:** $7,316 million\\n- **2024:** $9,245 million\\n- **Growth:** 55% from 2022 to 2024\\n\\n**Revenue Rest of World:**\\n- **2022:** $3,429 million\\n- **2023:** $4,251 million\\n- **2024:** $5,854 million\\n- **Growth:** 69% from 2022 to 2024\\n\\n### Key Insights:\\n- Revenue in the Rest of World grew the most significantly, followed by Europe and Asia-Pacific.\\n- The US & Canada and Europe regions saw moderate growth.\\n- Revenue in the US & Canada and Europe is relatively higher due to the size and maturity of the online and mobile advertising markets.\\n- Revenue growth in Asia-Pacific and Rest of World is attributed to lower monetization rates in these regions.'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "cell-10",
      "metadata": {
        "id": "cell-10"
      },
      "outputs": [],
      "source": [
        "# print(response)\n",
        "\n",
        "def generate_and_save_description(image_path: Path):\n",
        "    company_name = image_path.parent.parent.name\n",
        "    doc_name = image_path.parent.name\n",
        "\n",
        "    output_dir = Path(OUTPUT_DESC_DIR)/company_name/doc_name\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    desc_file = output_dir / f\"{image_path.stem}.md\"\n",
        "\n",
        "    if desc_file.exists():\n",
        "        return False\n",
        "\n",
        "    description = generate_image_description(image_path)\n",
        "    desc_file.write_text(description, encoding='utf-8')\n",
        "\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ec71f41f",
      "metadata": {
        "id": "ec71f41f"
      },
      "outputs": [],
      "source": [
        "image_path = Path(r'/content/drive/MyDrive/Udemy/KGP-TALKIE/Deep_Agent/resources/data/rag-data/images/meta/meta 10-k 2024/page_64.png')\n",
        "\n",
        "response = generate_and_save_description(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c1fed772",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1fed772",
        "outputId": "65b65c9e-f8d6-4db5-8769-d49432619374"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 77/77 [10:52<00:00,  8.47s/it]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "images_path = Path(IMAGES_DIR)\n",
        "image_files = list(images_path.rglob(\"page_*.png\"))\n",
        "\n",
        "for image_path in tqdm(image_files):\n",
        "    response = generate_and_save_description(image_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
